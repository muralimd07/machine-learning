{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1978, 1, 4, ..., 0, 0, 0],\n",
       "        [1958, 1, 3, ..., 0, 0, 0],\n",
       "        [2002, 1, 3, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1983, 1, 1, ..., 0, 0, 0],\n",
       "        [1981, 1, 3, ..., 0, 0, 0],\n",
       "        [1980, 1, 3, ..., 0, 0, 0]], dtype=object),\n",
       " array([ 270897.,  302404., 2519996., ...,   98280.,   98278.,  186480.]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Varies with sklearn version\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Load the data set\n",
    "df = pd.read_csv(\"ml_house_data_set.csv\")\n",
    "\n",
    "# Remove the fields from the data set that we don't want to include in our model\n",
    "del df['house_number']\n",
    "del df['unit_number']\n",
    "del df['street_name']\n",
    "del df['zip_code']\n",
    "\n",
    "# Replace categorical data with one-hot encoded data\n",
    "features_df = pd.get_dummies(df, columns=['garage_type', 'city'])\n",
    "\n",
    "# Remove the sale price from the feature data\n",
    "del features_df['sale_price']\n",
    "\n",
    "# Create the X and y arrays\n",
    "X = features_df.values\n",
    "y = df['sale_price'].values\n",
    "\n",
    "X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "features_df.to_csv('SampleX1.csv')\n",
    "df['sale_price'].to_csv('SampleY1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2008, 1, 3, ..., 0, 0, 0],\n",
       "        [2010, 2, 4, ..., 0, 0, 0],\n",
       "        [2007, 2, 3, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1909, 4, 5, ..., 0, 0, 0],\n",
       "        [2006, 2, 3, ..., 0, 0, 0],\n",
       "        [1971, 2, 5, ..., 0, 0, 0]], dtype=object),\n",
       " array([[2002, 1, 2, ..., 0, 0, 0],\n",
       "        [2006, 1, 3, ..., 0, 0, 0],\n",
       "        [1979, 1, 3, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1957, 2, 2, ..., 0, 0, 0],\n",
       "        [2004, 2, 5, ..., 0, 0, 0],\n",
       "        [1943, 1, 3, ..., 0, 0, 0]], dtype=object),\n",
       " array([692999., 440999., 277200., ..., 226799., 527937., 487617.]),\n",
       " array([296103., 239401., 434696., ..., 313741., 655202., 239404.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data set in a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 43)\n",
    "\n",
    "X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='huber', max_depth=6,\n",
       "                          max_features=0.1, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=9, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                          n_iter_no_change=None, presort='auto', random_state=0,\n",
       "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit regression model\n",
    "model = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=9,\n",
    "    max_features=0.1,\n",
    "    loss='huber',\n",
    "    random_state=0\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-33a4733ed321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the trained model to a file so we can use it in other programs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model/trained_house_classifier_model.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file so we can use it in other programs\n",
    "joblib.dump(model, 'model/trained_house_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Mean Absolute Error: 47928.4595\n",
      "Test Set Mean Absolute Error: 60093.5351\n"
     ]
    }
   ],
   "source": [
    "# Find the error rate on the training set\n",
    "mae = mean_absolute_error(y_train, model.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mae)\n",
    "\n",
    "# Find the error rate on the test set\n",
    "mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_New Robinton - 0.00%\n",
      "city_New Michele - 0.00%\n",
      "city_Martinezfort - 0.00%\n",
      "city_Julieberg - 0.00%\n",
      "city_Davidtown - 0.00%\n",
      "city_Lake Jennifer - 0.00%\n",
      "city_West Terrence - 0.01%\n",
      "city_West Brittanyview - 0.01%\n",
      "city_Rickytown - 0.01%\n",
      "city_Fosterberg - 0.01%\n",
      "city_East Justin - 0.01%\n",
      "city_South Stevenfurt - 0.01%\n",
      "city_Leahview - 0.03%\n",
      "city_Toddshire - 0.03%\n",
      "city_East Janiceville - 0.03%\n",
      "city_Wendybury - 0.04%\n",
      "city_Joshuafurt - 0.04%\n",
      "city_Brownport - 0.04%\n",
      "city_Amystad - 0.05%\n",
      "city_Port Adamtown - 0.05%\n",
      "city_Port Daniel - 0.05%\n",
      "city_Clarkberg - 0.09%\n",
      "city_West Lydia - 0.11%\n",
      "garage_type_detached - 0.11%\n",
      "city_Port Jonathanborough - 0.12%\n",
      "city_Davidfort - 0.13%\n",
      "city_West Gerald - 0.17%\n",
      "has_central_cooling - 0.17%\n",
      "city_Jenniferberg - 0.17%\n",
      "city_East Amychester - 0.21%\n",
      "city_Lewishaven - 0.22%\n",
      "city_Lake Carolyn - 0.24%\n",
      "city_North Erinville - 0.25%\n",
      "city_Morrisport - 0.26%\n",
      "city_East Lucas - 0.29%\n",
      "has_central_heating - 0.29%\n",
      "city_Lake Dariusborough - 0.36%\n",
      "city_Richardport - 0.36%\n",
      "city_West Gregoryview - 0.36%\n",
      "half_bathrooms - 0.40%\n",
      "city_West Ann - 0.42%\n",
      "city_South Anthony - 0.42%\n",
      "city_Hallfort - 0.52%\n",
      "city_Justinport - 0.59%\n",
      "city_Chadstad - 1.25%\n",
      "city_Scottberg - 1.30%\n",
      "city_Lake Christinaport - 1.42%\n",
      "city_Port Andrealand - 1.48%\n",
      "garage_type_none - 1.52%\n",
      "city_Lake Jack - 1.64%\n",
      "stories - 1.65%\n",
      "carport_sqft - 2.43%\n",
      "has_fireplace - 2.68%\n",
      "city_Jeffreyhaven - 3.15%\n",
      "full_bathrooms - 3.98%\n",
      "city_Coletown - 4.41%\n",
      "num_bedrooms - 5.15%\n",
      "has_pool - 5.22%\n",
      "year_built - 6.00%\n",
      "garage_type_attached - 7.68%\n",
      "garage_sqft - 10.50%\n",
      "total_sqft - 15.26%\n",
      "livable_sqft - 16.61%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# These are the feature labels from our data set\n",
    "feature_labels = np.array(['year_built', 'stories', 'num_bedrooms', 'full_bathrooms', 'half_bathrooms', 'livable_sqft', 'total_sqft', 'garage_sqft', 'carport_sqft', 'has_fireplace', 'has_pool', 'has_central_heating', 'has_central_cooling', 'garage_type_attached', 'garage_type_detached', 'garage_type_none', 'city_Amystad', 'city_Brownport', 'city_Chadstad', 'city_Clarkberg', 'city_Coletown', 'city_Davidfort', 'city_Davidtown', 'city_East Amychester', 'city_East Janiceville', 'city_East Justin', 'city_East Lucas', 'city_Fosterberg', 'city_Hallfort', 'city_Jeffreyhaven', 'city_Jenniferberg', 'city_Joshuafurt', 'city_Julieberg', 'city_Justinport', 'city_Lake Carolyn', 'city_Lake Christinaport', 'city_Lake Dariusborough', 'city_Lake Jack', 'city_Lake Jennifer', 'city_Leahview', 'city_Lewishaven', 'city_Martinezfort', 'city_Morrisport', 'city_New Michele', 'city_New Robinton', 'city_North Erinville', 'city_Port Adamtown', 'city_Port Andrealand', 'city_Port Daniel', 'city_Port Jonathanborough', 'city_Richardport', 'city_Rickytown', 'city_Scottberg', 'city_South Anthony', 'city_South Stevenfurt', 'city_Toddshire', 'city_Wendybury', 'city_West Ann', 'city_West Brittanyview', 'city_West Gerald', 'city_West Gregoryview', 'city_West Lydia', 'city_West Terrence'])\n",
    "\n",
    "# Load the trained model created with train_model.py\n",
    "model = joblib.load('model/trained_house_classifier_model.pkl')\n",
    "\n",
    "# Create a numpy array based on the model's feature importances\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Sort the feature labels based on the feature importance rankings from the model\n",
    "feauture_indexes_by_importance = importance.argsort()\n",
    "\n",
    "# Print each feature label, from most important to least important (reverse order)\n",
    "for index in feauture_indexes_by_importance:\n",
    "    print(\"{} - {:.2f}%\".format(feature_labels[index], (importance[index] * 100.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LinearRegression(copy_X=True, fit_intercept=True,\n",
       "                                           n_jobs=None, normalize=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (12811, 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-670ec76733a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mll\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (12811, 63)"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
